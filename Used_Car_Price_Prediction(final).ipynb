{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shefatmim01/Used-Car-Price-Prediction/blob/main/Used_Car_Price_Prediction(final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxX3pBzRJT53"
      },
      "source": [
        "# **Used Car Price Predection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm7qe92k2Hu7"
      },
      "source": [
        " **Import necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ROUMLLnM2O9_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6yBckK22TwO"
      },
      "source": [
        " **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0QjY8WR2bvq",
        "outputId": "0ab73739-4845-4f72-f98e-f99fae5749b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Australian Vehicle Prices.csv'\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZY4yR1v24bW"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "Nfy41zASoxRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWwhRKga3Pfs"
      },
      "source": [
        "### **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVBgI2My3Tst"
      },
      "outputs": [],
      "source": [
        "# data = data.drop(columns=[\"Unnamed: 0\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing Values Handling**"
      ],
      "metadata": {
        "id": "D_r4p3r0o5vO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ItygkUp3lq_"
      },
      "outputs": [],
      "source": [
        "print('Number of instances = %d' % (data.shape[0]))\n",
        "print('Number of attributes = %d' % (data.shape[1]))\n",
        "\n",
        "print('Number of missing values:')\n",
        "for col in data.columns:\n",
        "    print('\\t%s: %d' % (col,data[col].isna().sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjOxB1jN4Fjc"
      },
      "source": [
        "**Delete missing values in numerical columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooVBDma44InI"
      },
      "outputs": [],
      "source": [
        "data=data.dropna()\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1_MQr0O4PgY"
      },
      "outputs": [],
      "source": [
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0v7FO8z4dUm"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3tiyNug4hEP"
      },
      "source": [
        " **Duplicate Data Handeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUwcx0TF4gc6"
      },
      "outputs": [],
      "source": [
        "dups = data.duplicated()\n",
        "print('Number of duplicate rows = %d' % (dups.sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXvF1qWt467g"
      },
      "source": [
        "**Lebel Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQydB1Ax46gv"
      },
      "outputs": [],
      "source": [
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNxbkxzz5CPR"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoder for each categorical column\n",
        "label_encoders = {}\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le  # Store encoder for future use\n",
        "\n",
        "# Display the updated dataset with encoded categorical columns\n",
        "data.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting 'Year'  float to int\n",
        "data['Year'] = data['Year'].apply(np.int64)\n",
        "\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "3jlLNMGKj6XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLw2VXv0GISa"
      },
      "source": [
        "**EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2MSJsng5MFd"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHggYeeCGPKY"
      },
      "source": [
        "**Quartile**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsF_rw6x6GXx"
      },
      "outputs": [],
      "source": [
        "#creating dataset\n",
        "np.random.seed(10)\n",
        "Data=data[\"Price\"]\n",
        "print(Data)\n",
        "fig = plt.figure(figsize=(5, 7))\n",
        "\n",
        "#creating plot\n",
        "plt.boxplot(Data)\n",
        "\n",
        "#show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBVTWst76dwN"
      },
      "source": [
        " **Calculate The Correlation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ge9OpQq6fTJ"
      },
      "outputs": [],
      "source": [
        "data.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZBhe3sh6ms_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25,10))\n",
        "sns.heatmap(data.corr(), annot=True, fmt=\".2f\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "print(sns.__version__)"
      ],
      "metadata": {
        "id": "BffsrWnwnZ80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data, height=1.5);\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tajjflU3ndX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71hu0jWb7F3z"
      },
      "source": [
        "**Split Data into Training and Testing Sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mYl_Y2b7H55"
      },
      "outputs": [],
      "source": [
        "# Data split\n",
        "X = data.drop(columns=['Price','Brand','Car/Suv'])\n",
        "Y = data['Price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04i-ysD37Kth"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the training data, and only transform the test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert scaled data back to DataFrame (optional, for easier interpretation)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# Verify the scaling (mean should be close to 0, std should be close to 1 for X_train)\n",
        "print(\"Training data after scaling:\")\n",
        "print(X_train_scaled.describe())\n"
      ],
      "metadata": {
        "id": "Y0WMeSDAVpM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the training data, and only transform the test data\n",
        "X_train_minmax_scaled = min_max_scaler.fit_transform(X_train)\n",
        "X_test_minmax_scaled = min_max_scaler.transform(X_test)\n",
        "\n",
        "# Convert scaled data back to DataFrame (optional, for easier interpretation)\n",
        "X_train_minmax_scaled = pd.DataFrame(X_train_minmax_scaled, columns=X_train.columns)\n",
        "X_test_minmax_scaled = pd.DataFrame(X_test_minmax_scaled, columns=X_test.columns)\n",
        "\n",
        "# Verify the scaling (values should now be between 0 and 1)\n",
        "print(\"Training data after MinMax scaling:\")\n",
        "print(X_train_minmax_scaled.describe())\n"
      ],
      "metadata": {
        "id": "Z5uXg_u9WIci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDAAcYhE7gPs"
      },
      "source": [
        "**Define a function for model evaluation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsKogMR7-Dq_"
      },
      "source": [
        " **linear regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcO6IDdV9xoI"
      },
      "outputs": [],
      "source": [
        "# Creating and training the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "Y_train_pred = model.predict(X_train)\n",
        "Y_test_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMTbF_TS-RK0"
      },
      "outputs": [],
      "source": [
        "print(\"Linear Regression Model\\n\")\n",
        "\n",
        "# Evaluation Metrics for Training Data\n",
        "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(\"\\tTraining Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {train_mae}\")\n",
        "print(f\"\\t\\tMSE: {train_mse}\")\n",
        "print(f\"\\t\\tRMSE: {train_rmse}\")\n",
        "print(f\"\\t\\tR²: {train_r2*100}\")\n",
        "\n",
        "\n",
        "# Evaluation Metrics for Testing Data\n",
        "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
        "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(\"\\n\\tTesting Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {test_mae}\")\n",
        "print(f\"\\t\\tMSE: {test_mse}\")\n",
        "print(f\"\\t\\tRMSE: {test_rmse}\")\n",
        "print(f\"\\t\\tR²: {test_r2*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xoFqc6f-6vo"
      },
      "source": [
        "**Visualize the actual prices and Predicted prices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlrSbP8N-W1W"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# Scatter plot for Training Data\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.6)\n",
        "plt.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTraining Data(Linear Regression Model)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Scatter plot for Testing Data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(Y_test, Y_test_pred, color='green', alpha=0.6)\n",
        "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTesting Data(Linear Regression Model)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCLuGQ1H_Dcs"
      },
      "source": [
        "**Lasso Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kxsNhTD_LS_"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# loading the linear regression model\n",
        "lass_reg_model = Lasso()\n",
        "lass_reg_model.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD45hY_X_RYD"
      },
      "outputs": [],
      "source": [
        "# Evaluation Metrics for Training Data\n",
        "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(Y_train, Y_train_pred)\n",
        "print(\"Lasso Regression -\\n\")\n",
        "print(\"\\tTraining Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {train_mae}\")\n",
        "print(f\"\\t\\tMSE: {train_mse}\")\n",
        "print(f\"\\t\\tRMSE: {train_rmse}\")\n",
        "print(f\"\\t\\tR²: {train_r2*100}\")\n",
        "\n",
        "# Evaluation Metrics for Testing Data\n",
        "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
        "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "print(\"\\n\\tTesting Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {test_mae}\")\n",
        "print(f\"\\t\\tMSE: {test_mse}\")\n",
        "print(f\"\\t\\tRMSE: {test_rmse}\")\n",
        "print(f\"\\t\\tR²: {test_r2*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPgcU4en_qk1"
      },
      "source": [
        "**Visualize the actual prices and Predicted prices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wUi_THF_vxW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# Plotting Actual vs Predicted for Training Data\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.6)\n",
        "plt.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTraining Data (Lasso Regression)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Plotting Actual vs Predicted for Testing Data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(Y_test, Y_test_pred, color='green', alpha=0.6)\n",
        "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTesting Data (Lasso Regression)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdPckmCg_yKC"
      },
      "source": [
        "**Random Forest Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu-V8xFS_1I4"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Creating and training the Random Forest Regression model\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(X_train, Y_train)\n",
        "\n",
        "# Making predictions\n",
        "Y_train_pred = rf.predict(X_train)\n",
        "Y_test_pred = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aktAKNQ_7jD"
      },
      "outputs": [],
      "source": [
        "# Evaluation Metrics for Training Data\n",
        "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "\n",
        "print(\"Random Forest Regression\\n\")\n",
        "# Printing the results\n",
        "print(\"\\tTraining Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {train_mae}\")\n",
        "print(f\"\\t\\tMSE: {train_mse}\")\n",
        "print(f\"\\t\\tRMSE: {train_rmse}\")\n",
        "print(f\"\\t\\tR²: {train_r2*100}\")\n",
        "\n",
        "# Evaluation Metrics for Testing Data\n",
        "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
        "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "print(\"\\n\\tTesting Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {test_mae}\")\n",
        "print(f\"\\t\\tMSE: {test_mse}\")\n",
        "print(f\"\\t\\tRMSE: {test_rmse}\")\n",
        "print(f\"\\t\\tR²: {test_r2*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYXq7AXIAbT5"
      },
      "source": [
        "**Visualize the actual prices and Predicted prices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBjAXwg6Ad-G"
      },
      "outputs": [],
      "source": [
        "# Plotting Actual vs Predicted for Training Data\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.6)\n",
        "plt.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTraining Data (Random Forest)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Plotting Actual vs Predicted for Testing Data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(Y_test, Y_test_pred, color='green', alpha=0.6)\n",
        "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTesting Data (Random Forest)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhoVCuvAAj91"
      },
      "source": [
        " **XGBoost Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXD0wMkqAoP5"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Creating and training the XGBoost Regression model\n",
        "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=10, random_state=1)\n",
        "xgb.fit(X_train, Y_train)\n",
        "\n",
        "# Making predictions\n",
        "Y_train_pred = xgb.predict(X_train)\n",
        "Y_test_pred = xgb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysdd0np5At3W"
      },
      "outputs": [],
      "source": [
        "# Evaluation Metrics for Training Data\n",
        "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "print(\"XGBoost Regression-\\n\")\n",
        "\n",
        "# Printing the results\n",
        "print(\"\\tTraining Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {train_mae}\")\n",
        "print(f\"\\t\\tMSE: {train_mse}\")\n",
        "print(f\"\\t\\tRMSE: {train_rmse}\")\n",
        "print(f\"\\t\\tR²: {train_r2*100}\")\n",
        "\n",
        "# Evaluation Metrics for Testing Data\n",
        "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
        "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "print(\"\\n\\tTesting Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {test_mae}\")\n",
        "print(f\"\\t\\tMSE: {test_mse}\")\n",
        "print(f\"\\t\\tRMSE: {test_rmse}\")\n",
        "print(f\"\\t\\tR²: {test_r2*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u7eKMMgBFRZ"
      },
      "source": [
        "**Visualization Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRbekZ62BIU5"
      },
      "outputs": [],
      "source": [
        "# Plotting Actual vs Predicted for Training Data\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.6)\n",
        "plt.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTraining Data (XGBoost Regression)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Plotting Actual vs Predicted for Testing Data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(Y_test, Y_test_pred, color='green', alpha=0.6)\n",
        "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTesting Data (XGBoost Regression)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhNcLz32BTQX"
      },
      "source": [
        "**Robust Regression (RANSAC)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i66ZUtbBVDl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDrwGRxmBW0M"
      },
      "outputs": [],
      "source": [
        "# Feature Scaling - RANSAC can be sensitive to the scale of features, so we scale them\n",
        "scaler_X = StandardScaler()\n",
        "scaler_Y = StandardScaler()\n",
        "\n",
        "# Scaling the features\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Scaling the target variable\n",
        "Y_train_scaled = scaler_Y.fit_transform(Y_train.values.reshape(-1, 1))\n",
        "Y_test_scaled = scaler_Y.transform(Y_test.values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and training the RANSAC model\n",
        "ransac = RANSACRegressor(random_state=2)\n",
        "ransac.fit(X_train_scaled, Y_train_scaled.ravel())  # Use ravel to convert target to 1D\n",
        "\n",
        "# Making predictions\n",
        "Y_train_pred_scaled = ransac.predict(X_train_scaled)\n",
        "Y_test_pred_scaled = ransac.predict(X_test_scaled)\n",
        "\n",
        "# Inverse transform the scaled predictions to get them back to the original scale\n",
        "Y_train_pred = scaler_Y.inverse_transform(Y_train_pred_scaled.reshape(-1, 1))\n",
        "Y_test_pred = scaler_Y.inverse_transform(Y_test_pred_scaled.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "kjn_Zpetrtlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gH8-mI9UBfK1"
      },
      "outputs": [],
      "source": [
        "# Evaluation Metrics for Training Data\n",
        "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "\n",
        "# Evaluation Metrics for Testing Data\n",
        "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
        "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "print(\"Robust Regression (RANSAC) -\\n\")\n",
        "\n",
        "# Printing the results\n",
        "print(\"\\tTraining Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {train_mae}\")\n",
        "print(f\"\\t\\tMSE: {train_mse}\")\n",
        "print(f\"\\t\\tRMSE: {train_rmse}\")\n",
        "print(f\"\\t\\tR²: {-train_r2*100}\")\n",
        "\n",
        "print(\"\\n\\tTesting Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {test_mae}\")\n",
        "print(f\"\\t\\tMSE: {test_mse}\")\n",
        "print(f\"\\t\\tRMSE: {test_rmse}\")\n",
        "print(f\"\\t\\tR²: {test_r2*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FA4x18wDhSQ"
      },
      "outputs": [],
      "source": [
        "# Plotting Actual vs Predicted for Training Data\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.6)\n",
        "plt.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTraining Data (Robust Regression (RANSAC))\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Plotting Actual vs Predicted for Testing Data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(Y_test, Y_test_pred, color='green', alpha=0.6)\n",
        "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTesting Data (Robust Regression (RANSAC))\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgHb1KuwC_55"
      },
      "source": [
        " **Polynomial Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpqytCJTB1Mq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=2)\n",
        "\n",
        "# Feature Scaling - Polynomial Regression can benefit from scaling the features\n",
        "scaler_X = StandardScaler()\n",
        "scaler_Y = StandardScaler()\n",
        "\n",
        "# Scaling the features\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Scaling the target variable\n",
        "Y_train_scaled = scaler_Y.fit_transform(Y_train.values.reshape(-1, 1))\n",
        "Y_test_scaled = scaler_Y.transform(Y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Create Polynomial features (degree can be changed based on the need)\n",
        "degree = 3  # You can tune this value\n",
        "poly = PolynomialFeatures(degree=degree)\n",
        "X_train_poly = poly.fit_transform(X_train_scaled)\n",
        "X_test_poly = poly.transform(X_test_scaled)\n",
        "\n",
        "# Create and train the linear regression model on the polynomial features\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_poly, Y_train_scaled)\n",
        "\n",
        "# Making predictions\n",
        "Y_train_pred_scaled = lin_reg.predict(X_train_poly)\n",
        "Y_test_pred_scaled = lin_reg.predict(X_test_poly)\n",
        "\n",
        "# Inverse transform the scaled predictions to get them back to the original scale\n",
        "Y_train_pred = scaler_Y.inverse_transform(Y_train_pred_scaled.reshape(-1, 1))\n",
        "Y_test_pred = scaler_Y.inverse_transform(Y_test_pred_scaled.reshape(-1, 1))\n",
        "\n",
        "# Evaluation Metrics for Training Data\n",
        "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "# Evaluation Metrics for Testing Data\n",
        "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
        "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(Y_test, Y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Polynomial Regression (Degree {degree})-\\n\")\n",
        "# Printing the results\n",
        "print(f\"\\tTraining Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {train_mae}\")\n",
        "print(f\"\\t\\tMSE: {train_mse}\")\n",
        "print(f\"\\t\\tRMSE: {train_rmse}\")\n",
        "print(f\"\\t\\tR²: {train_r2*100}\")\n",
        "\n",
        "print(\"\\n\\tTesting Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {test_mae}\")\n",
        "print(f\"\\t\\tMSE: {test_mse}\")\n",
        "print(f\"\\t\\tRMSE: {test_rmse}\")\n",
        "print(f\"\\t\\tR²: {test_r2*100}\")"
      ],
      "metadata": {
        "id": "Np3coUHrr8Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLjMB_v-Ds5N"
      },
      "outputs": [],
      "source": [
        "# Plotting Actual vs Predicted for Training Data\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.6)\n",
        "plt.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTraining Data (Polynomial Regression)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Plotting Actual vs Predicted for Testing Data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(Y_test, Y_test_pred, color='green', alpha=0.6)\n",
        "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTesting Data (Polinomial Regression)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIqtSOvkDaJe"
      },
      "source": [
        "**Bayesian Ridge Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7FYY3IUCfgu"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=2)\n",
        "\n",
        "# Feature Scaling - Bayesian Ridge Regression can benefit from scaling the features\n",
        "scaler_X = StandardScaler()\n",
        "scaler_Y = StandardScaler()\n",
        "\n",
        "# Scaling the features\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Scaling the target variable\n",
        "Y_train_scaled = scaler_Y.fit_transform(Y_train.values.reshape(-1, 1))\n",
        "Y_test_scaled = scaler_Y.transform(Y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Create and train the Bayesian Ridge Regression model\n",
        "bayesian_ridge = BayesianRidge()\n",
        "bayesian_ridge.fit(X_train_scaled, Y_train_scaled.ravel())\n",
        "\n",
        "# Making predictions\n",
        "Y_train_pred_scaled = bayesian_ridge.predict(X_train_scaled)\n",
        "Y_test_pred_scaled = bayesian_ridge.predict(X_test_scaled)\n",
        "\n",
        "# Inverse transform the scaled predictions to get them back to the original scale\n",
        "Y_train_pred = scaler_Y.inverse_transform(Y_train_pred_scaled.reshape(-1, 1))\n",
        "Y_test_pred = scaler_Y.inverse_transform(Y_test_pred_scaled.reshape(-1, 1))\n",
        "\n",
        "# Evaluation Metrics for Training Data\n",
        "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "# Evaluation Metrics for Testing Data\n",
        "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
        "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "\n",
        "print(\"Bayesian Ridge Regression-\\n\")\n",
        "# Printing the results\n",
        "print(\"\\tTraining Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {train_mae}\")\n",
        "print(f\"\\t\\tMSE: {train_mse}\")\n",
        "print(f\"\\t\\tRMSE: {train_rmse}\")\n",
        "print(f\"\\t\\tR²: {train_r2*100}\")\n",
        "\n",
        "print(\"\\n\\tTesting Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {test_mae}\")\n",
        "print(f\"\\t\\tMSE: {test_mse}\")\n",
        "print(f\"\\t\\tRMSE: {test_rmse}\")\n",
        "print(f\"\\t\\tR²: {test_r2*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXolq2ihDKVM"
      },
      "outputs": [],
      "source": [
        "# Plotting Actual vs Predicted for Training Data\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(Y_train, Y_train_pred, color='blue', alpha=0.6)\n",
        "plt.plot([Y_train.min(), Y_train.max()], [Y_train.min(), Y_train.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTraining Data (Bayesian Ridge Regression)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Plotting Actual vs Predicted for Testing Data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(Y_test, Y_test_pred, color='green', alpha=0.6)\n",
        "plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Actual vs Predicted - \\nTesting Data (Bayesian Ridge Regression)\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid()\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVV8jUzAF3dF"
      },
      "source": [
        "**Determine the Best Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "ixvZp2ai9kCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the intercept term\n",
        "x = np.column_stack((np.ones(X.shape[0]), X))"
      ],
      "metadata": {
        "id": "hd_novxn-h0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the coefficients (beta)\n",
        "beta = np.linalg.inv(x.T @ x) @ x.T @ Y"
      ],
      "metadata": {
        "id": "usfCHFnF-z32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the predictions\n",
        "y_pred = x @ beta"
      ],
      "metadata": {
        "id": "eOIXuEhw_B8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate residuals\n",
        "residuals = Y - y_pred\n"
      ],
      "metadata": {
        "id": "G5dry1WQ_LNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the variance and standard error\n",
        "sigma_squared = np.sum(residuals**2) / (len(Y) - 2)\n",
        "standard_error = np.sqrt(np.diagonal(sigma_squared * np.linalg.inv(x.T @ x)))"
      ],
      "metadata": {
        "id": "Vs3UzDNI_Roq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate t-statistics\n",
        "t_stats = beta / standard_error\n"
      ],
      "metadata": {
        "id": "jZRKKybj_aEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate p-values\n",
        "p_values = [2 * (1 - stats.t.cdf(np.abs(t), len(Y) - 2)) for t in t_stats]"
      ],
      "metadata": {
        "id": "TBTSknBx_eB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"Coefficients:\", beta)\n",
        "print(\"P-values:\", p_values)"
      ],
      "metadata": {
        "id": "Ky2984d2_iT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **P_ Value for Random forest Regression.**"
      ],
      "metadata": {
        "id": "sAOWJ-eQstE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fitting the Random Forest model\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, Y_train)\n",
        "\n",
        "# Permutation importance\n",
        "perm_importance = permutation_importance(rf, X_test, Y_test, n_repeats=30, random_state=42)\n",
        "\n",
        "# Display feature importance and approximate p-values\n",
        "feature_importances = perm_importance.importances_mean\n",
        "p_values = [1.0 if imp <= 0 else (sum(perm_importance.importances[i] <= 0) / len(perm_importance.importances[i]))\n",
        "            for i, imp in enumerate(perm_importance.importances_mean)]\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Importance\": feature_importances,\n",
        "    \"P-value Approximation\": p_values\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "XSazDNvPsdsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **P_ Value for XGboost Regression.**"
      ],
      "metadata": {
        "id": "_8R56341Txve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fitting the Random Forest model\n",
        "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=10, random_state=1)\n",
        "xgb.fit(X_train, Y_train)\n",
        "\n",
        "# Permutation importance\n",
        "perm_importance = permutation_importance(xgb, X_test, Y_test, n_repeats=30, random_state=42)\n",
        "\n",
        "# Display feature importance and approximate p-values\n",
        "feature_importances = perm_importance.importances_mean\n",
        "p_values = [1.0 if imp <= 0 else (sum(perm_importance.importances[i] <= 0) / len(perm_importance.importances[i]))\n",
        "            for i, imp in enumerate(perm_importance.importances_mean)]\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Importance\": feature_importances,\n",
        "    \"P-value Approximation\": p_values\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "fkO-lwtyTvWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mSpL2kSJvx_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Actual vs Predicted Values**"
      ],
      "metadata": {
        "id": "VnhPlWrduXYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual vs Predicted Values\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Step 1: Scale the target variable (optional if scaling needed)\n",
        "scaler = MinMaxScaler()\n",
        "Y_scaled = scaler.fit_transform(Y.values.reshape(-1, 1))\n",
        "\n",
        "# Step 2: Split the data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, Y_train.ravel())\n",
        "\n",
        "# Step 4: Train XGBoost model\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "xgb_model.fit(X_train, Y_train.ravel())\n",
        "\n",
        "# Step 5: Make predictions\n",
        "Y_pred_rf = rf_model.predict(X_test)\n",
        "Y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Step 6: Inverse transform predictions (if scaled)\n",
        "Y_test_original = scaler.inverse_transform(Y_test)\n",
        "Y_pred_rf_original = scaler.inverse_transform(Y_pred_rf.reshape(-1, 1))\n",
        "Y_pred_xgb_original = scaler.inverse_transform(Y_pred_xgb.reshape(-1, 1))\n",
        "\n",
        "# Step 7: Plot Actual vs Predicted values\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(range(len(Y_test_original)), Y_test_original, label='Actual Values', color='blue', alpha=0.7)\n",
        "plt.plot(range(len(Y_test_original)), Y_pred_rf_original, label='Random Forest Predictions', color='orange', linestyle='--')\n",
        "plt.plot(range(len(Y_test_original)), Y_pred_xgb_original, label='XGBoost Predictions', color='green', linestyle='--')\n",
        "plt.title('Actual vs Predicted Values')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Target Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RBjx02vRViAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ensemble**"
      ],
      "metadata": {
        "id": "Ei-K3eACDFTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To create an ensemble of the three regression models (`RandomForestRegressor`, `XGBRegressor`, and `RANSACRegressor`), we can use a stacking technique. Stacking involves training a meta-model that combines the predictions from the base models to improve the overall performance.\n",
        "\n",
        "# Here is the code to implement the ensemble using stacking:\n",
        "\n",
        "# ```python\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression  # Meta-model\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Random Forest model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# XGBoost model\n",
        "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=10, random_state=1)\n",
        "\n",
        "# RANSAC model (with scaling pipeline)\n",
        "ransac_pipeline = Pipeline([\n",
        "    ('scaler_X', StandardScaler()),\n",
        "    ('ransac', RANSACRegressor(random_state=2))\n",
        "])\n",
        "\n",
        "# Creating the Stacking Regressor\n",
        "stacking_regressor = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('random_forest', rf),\n",
        "        ('xgboost', xgb),\n",
        "        ('ransac', ransac_pipeline)\n",
        "    ],\n",
        "    final_estimator=LinearRegression(),  # Meta-model\n",
        "    passthrough=False  # Use base model predictions as inputs to the meta-model\n",
        ")\n",
        "\n",
        "# Train the Stacking Regressor\n",
        "stacking_regressor.fit(X_train, Y_train)\n",
        "\n",
        "# Making predictions\n",
        "Y_train_pred = stacking_regressor.predict(X_train)\n",
        "Y_test_pred = stacking_regressor.predict(X_test)\n",
        "\n",
        "# Evaluation Metrics for Training Data\n",
        "train_mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "train_mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "print(\"Stacking Regression -\\n\")\n",
        "# Printing the results\n",
        "print(\"\\tTraining Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {train_mae}\")\n",
        "print(f\"\\t\\tMSE: {train_mse}\")\n",
        "print(f\"\\t\\tRMSE: {train_rmse}\")\n",
        "print(f\"\\t\\tR²: {train_r2*100}\")\n",
        "\n",
        "# Evaluation Metrics for Testing Data\n",
        "test_mae = mean_absolute_error(Y_test, Y_test_pred)\n",
        "test_mse = mean_squared_error(Y_test, Y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "print(\"\\n\\tTesting Data Evaluation:\")\n",
        "print(f\"\\t\\tMAE: {test_mae}\")\n",
        "print(f\"\\t\\tMSE: {test_mse}\")\n",
        "print(f\"\\t\\tRMSE: {test_rmse}\")\n",
        "print(f\"\\t\\tR²: {test_r2*100}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "seE-I_Oqx43h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Evaluation metrics for visualization\n",
        "metrics = ['MAE', 'MSE', 'RMSE', 'R²']\n",
        "train_scores = [train_mae, train_mse, train_rmse, train_r2 * 100]  # R² as percentage\n",
        "test_scores = [test_mae, test_mse, test_rmse, test_r2 * 100]       # R² as percentage\n",
        "\n",
        "x = np.arange(len(metrics))  # Number of metrics\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "bar_width = 0.35\n",
        "\n",
        "# Bar plots for Training and Testing scores\n",
        "plt.bar(x - bar_width/2, train_scores, width=bar_width, color='skyblue', label='Training')\n",
        "plt.bar(x + bar_width/2, test_scores, width=bar_width, color='salmon', label='Testing')\n",
        "\n",
        "# Adding annotations to the bars\n",
        "for i in range(len(metrics)):\n",
        "    plt.text(x[i] - bar_width/2, train_scores[i] + 0.5, f\"{train_scores[i]:.2f}\", ha='center', va='bottom', fontsize=10)\n",
        "    plt.text(x[i] + bar_width/2, test_scores[i] + 0.5, f\"{test_scores[i]:.2f}\", ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Customizing the plot\n",
        "plt.xticks(x, metrics, fontsize=12)\n",
        "plt.xlabel('Metrics', fontsize=14)\n",
        "plt.ylabel('Scores', fontsize=14)\n",
        "plt.title('Performance of Stacking Regressor on Training and Testing Data', fontsize=16)\n",
        "plt.legend(fontsize=12)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bCMyWZKe9Q9X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP+2XFg0eYGpKDzkU0zux1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}